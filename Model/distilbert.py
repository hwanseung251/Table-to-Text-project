# -*- coding: utf-8 -*-
"""distilBert.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LU881gacEPCzbu-VWMRYl2_u-Nfc9JAU
"""

import pandas as pd
import torch
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, DistilBertForSequenceClassification
from sklearn.metrics import f1_score, matthews_corrcoef
from datasets import Dataset
from sklearn.model_selection import train_test_split

train_data = pd.read_excel('/content/sample_data/train_backaug.xlsx', index_col = 0)
train_data

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, matthews_corrcoef
from transformers import BertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments
from datasets import Dataset
import torch
import torch.nn as nn

# 데이터셋 로드 및 준비
train_data = pd.read_excel('/content/sample_data/train_backaug.xlsx', index_col=0)
val_data = pd.read_excel('/content/sample_data/val_data.xlsx')
test_data = pd.read_excel('/content/sample_data/test_data.xlsx')

# 레이블 매핑 정의
label_mapping = {'no': 0, 'yes': 1}

# 레이블을 문자열에서 정수로 변환
train_data['y'] = train_data['y'].map(label_mapping)
val_data['y'] = val_data['y'].map(label_mapping)
test_data['y'] = test_data['y'].map(label_mapping)

# 클래스별 데이터 수 확인 (pandas 사용)
class_counts = train_data['y'].value_counts().to_dict()

# 클래스 가중치 계산 (다수 클래스는 더 작은 가중치를 가짐)
class_weights = torch.tensor([1.0 / class_counts[0], 1.0 / class_counts[1]], device='cuda' if torch.cuda.is_available() else 'cpu')

# Tokenizer와 모델 로드
tokenizer = BertTokenizer.from_pretrained('distilbert-base-uncased')
model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(label_mapping))

# Gradient checkpointing 활성화
model.config.gradient_checkpointing = True

# GPU 사용 가능 여부 확인 및 설정
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
print(f'Using device: {device}')

# 모델을 GPU로 이동
model.to(device)

# Tokenizer 함수
def tokenize_function(examples):
    return tokenizer(examples['text'], padding="max_length", truncation=True, max_length=128)

# Dataset을 Hugging Face의 Dataset 객체로 변환
train_data = Dataset.from_pandas(train_data)
val_data = Dataset.from_pandas(val_data)
test_data = Dataset.from_pandas(test_data)

# 'y' 열을 'labels'로 변환
train_data = train_data.map(lambda x: {'labels': x['y']})
val_data = val_data.map(lambda x: {'labels': x['y']})
test_data = test_data.map(lambda x: {'labels': x['y']})

# 데이터셋에 토크나이징 적용
train_data = train_data.map(tokenize_function, batched=True)
val_data = val_data.map(tokenize_function, batched=True)
test_data = test_data.map(tokenize_function, batched=True)

# 커스텀 Trainer 정의 (손실 함수에 클래스 가중치 적용)
class WeightedTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False):
        labels = inputs.get("labels")
        outputs = model(**inputs)
        logits = outputs.get("logits")

        # 가중치가 적용된 CrossEntropyLoss
        loss_fn = nn.CrossEntropyLoss(weight=class_weights)
        loss = loss_fn(logits, labels)

        return (loss, outputs) if return_outputs else loss

# Trainer의 인자 설정
training_args = TrainingArguments(
    output_dir='./results',
    evaluation_strategy="epoch",
    save_strategy="epoch",
    per_device_train_batch_size=64,
    per_device_eval_batch_size=64,
    num_train_epochs=10,
    weight_decay=0.01,
    warmup_steps=500,
    learning_rate=3e-5,
    logging_dir='./logs',
    logging_steps=50,
    save_total_limit=2,
    load_best_model_at_end=True,
    report_to=[]
)

# 평가 함수 정의
def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    f1 = f1_score(labels, preds, average='binary')
    mcc = matthews_corrcoef(labels, preds)
    return {"f1": f1, "mcc": mcc}

# WeightedTrainer 사용
trainer = WeightedTrainer(
    model=model,
    args=training_args,
    train_dataset=train_data,
    eval_dataset=val_data,
    compute_metrics=compute_metrics,
)

# 모델 학습
trainer.train()

# 테스트 데이터 평가
# test_results = trainer.evaluate(test_data)
# print(test_results)

# Validation 데이터셋에 대한 예측
val_predictions = trainer.predict(val_data)
val_preds = val_predictions.predictions.argmax(-1)  # 각 샘플에 대한 예측 클래스 (0 또는 1)
val_pred_proba = torch.softmax(torch.tensor(val_predictions.predictions), dim=1).numpy()  # 각 샘플에 대한 예측 확률

# Test 데이터셋에 대한 예측
test_predictions = trainer.predict(test_data)
test_preds = test_predictions.predictions.argmax(-1)  # 각 샘플에 대한 예측 클래스 (0 또는 1)
test_pred_proba = torch.softmax(torch.tensor(test_predictions.predictions), dim=1).numpy()  # 각 샘플에 대한 예측 확률

# 예측 결과와 확률 출력
print("Validation Predictions (Labels):", val_preds)
print("Validation Predictions (Probabilities):", val_pred_proba)

print("Test Predictions (Labels):", test_preds)
print("Test Predictions (Probabilities):", test_pred_proba)

import numpy as np
import pandas as pd

# NumPy 배열 출력 옵션 설정 (축약되지 않게)
np.set_printoptions(threshold=np.inf, suppress=True)

# Validation 데이터셋 예측 결과
val_predictions = trainer.predict(val_data)
val_preds = val_predictions.predictions.argmax(-1)  # 각 샘플에 대한 예측 클래스 (0 또는 1)
val_pred_proba = torch.softmax(torch.tensor(val_predictions.predictions), dim=1).numpy()  # 각 샘플에 대한 예측 확률

# Test 데이터셋 예측 결과
test_predictions = trainer.predict(test_data)
test_preds = test_predictions.predictions.argmax(-1)  # 각 샘플에 대한 예측 클래스 (0 또는 1)
test_pred_proba = torch.softmax(torch.tensor(test_predictions.predictions), dim=1).numpy()  # 각 샘플에 대한 예측 확률

# Validation 예측 결과를 DataFrame으로 변환
val_df = pd.DataFrame({
    'Predicted Label': val_preds,
    'Class 0 Probability': val_pred_proba[:, 0],
    'Class 1 Probability': val_pred_proba[:, 1]
})

# Test 예측 결과를 DataFrame으로 변환
test_df = pd.DataFrame({
    'Predicted Label': test_preds,
    'Class 0 Probability': test_pred_proba[:, 0],
    'Class 1 Probability': test_pred_proba[:, 1]
})

# Validation 데이터셋 출력
print("Validation Data Predictions:")
print(val_df)

# Test 데이터셋 출력
print("Test Data Predictions:")
print(test_df)

import pandas as pd

# Validation 데이터셋 예측 결과
val_predictions = trainer.predict(val_data)
val_preds = val_predictions.predictions.argmax(-1)  # 각 샘플에 대한 예측 클래스 (0 또는 1)
val_pred_proba = torch.softmax(torch.tensor(val_predictions.predictions), dim=1).numpy()  # 각 샘플에 대한 예측 확률

# Test 데이터셋 예측 결과
test_predictions = trainer.predict(test_data)
test_preds = test_predictions.predictions.argmax(-1)  # 각 샘플에 대한 예측 클래스 (0 또는 1)
test_pred_proba = torch.softmax(torch.tensor(test_predictions.predictions), dim=1).numpy()  # 각 샘플에 대한 예측 확률

# Validation 예측 결과를 DataFrame으로 변환
val_df = pd.DataFrame({
    'Predicted Label': val_preds,
    'Class 0 Probability': val_pred_proba[:, 0],
    'Class 1 Probability': val_pred_proba[:, 1]
})

# Test 예측 결과를 DataFrame으로 변환
test_df = pd.DataFrame({
    'Predicted Label': test_preds,
    'Class 0 Probability': test_pred_proba[:, 0],
    'Class 1 Probability': test_pred_proba[:, 1]
})

# Validation 데이터 예측 결과를 CSV 파일로 저장
val_df.to_csv('validation_predictions.csv', index=False)

# Test 데이터 예측 결과를 CSV 파일로 저장
test_df.to_csv('test_predictions.csv', index=False)

print("Validation and Test predictions saved to CSV files.")

# 평가 결과 출력 (평가 후 최종 성능 확인)
eval_results = trainer.evaluate()


print(f"Validation Loss: {eval_results['eval_loss']}")
print(f"Validation F1: {eval_results['eval_f1']}")
print(f"Validation MCC: {eval_results['eval_mcc']}")

test_results = trainer.evaluate(eval_dataset=test_data)

print(f"Test Loss: {test_results['eval_loss']}")
print(f"Test F1: {test_results['eval_f1']}")
print(f"Test MCC: {test_results['eval_mcc']}")

output_dir = "./trained_model"

# 모델 저장
model.save_pretrained(output_dir)

# 토크나이저 저장
tokenizer.save_pretrained(output_dir)

# 모델 학습 후 저장
trainer.save_model(r"C:\Users\ojw19\Desktop\conference")

